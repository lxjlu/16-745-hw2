{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.activate(joinpath(@__DIR__,\"..\")); Pkg.instantiate()\n",
    "using LinearAlgebra\n",
    "using SparseArrays\n",
    "using ForwardDiff\n",
    "using OSQP\n",
    "using RobotDynamics\n",
    "using RobotZoo: PlanarRocket\n",
    "using RobotZoo\n",
    "using StaticArrays\n",
    "using Plots\n",
    "include(\"rocket.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Writing an MPC Controller (50 pts)\n",
    "In this problem we'll compare the performance of LQR with a QP-based MPC controller for landing a rocket booster. \n",
    "\n",
    "## The Dynamics\n",
    "We'll be solving a simplified version of the rocket soft landing problem. We'll only be considering a planar version where we control the lateral and vertical movement of the rocket by rotating the thrust vector. The dynamics are as follows:\n",
    "\n",
    "$$ \n",
    "x = \\begin{bmatrix} p_x \\\\ p_z \\\\ \\theta \\\\ v_x \\\\ v_z \\\\ \\omega \\\\ T \\\\ \\phi \\end{bmatrix}, \\quad\n",
    "u = \\begin{bmatrix} \\dot{T} \\\\ \\dot{\\phi} \\end{bmatrix}, \\quad\n",
    "\\dot{x} = \\begin{bmatrix}\n",
    "v_z \\\\ v_z \\\\ \\omega \\\\\n",
    "\\frac{T}{m} \\cos{(\\theta + \\phi)} \\\\ \n",
    "\\frac{T}{m} \\sin{(\\theta + \\phi)} \\\\\n",
    "\\frac{T}{2J} L \\sin(\\phi) \\\\\n",
    "\\dot{T} \\\\ \\dot{\\phi}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where $p_x$ is the lateral displacement, $p_z$ is the altitude, $\\theta$ is the roll angle, $v_x$ and $v_z$ are the linear velocities, $\\omega$ is the roll rate, $T$ is the total thrust, $\\phi$ is the thrust angle, $\\dot{T}$ and $\\dot{\\phi}$ are the thrust and thrust angle rates, $m$ is the mass, $J$ is the moment of inertia, $L$ is the distance from the thruster to the center of mass, and $g$ is gravity.\n",
    "\n",
    "To keep our solution stable and safe, we'll saturate our thrust to be between 75%-150% of the nominal gravity-compensating thrust, our thrust angle with $\\pm$10 degrees, and our roll angle between $\\pm$5 degrees.\n",
    "\n",
    "Again, we've already defined a `RobotDynamics` model that implements these dynamics for you, but it's helpful to understand the dynamics model you're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planar Rocket model\n",
    "model = PlanarRocket(max_roll=5.0)\n",
    "n,m = state_dim(model), control_dim(model)\n",
    "xeq = [zeros(6); model.m*model.g; 0]\n",
    "ueq = zeros(2) \n",
    "norm(dynamics(model, xeq, ueq)) ≈ 0 # make sure it's an equilibrium point\n",
    "dt = 0.1  # time step (s)\n",
    "tf = 25   # time horizon (s)\n",
    "N = Int(tf / dt) + 1\n",
    "\n",
    "# Evaluate the continuous and discrete Jacobians\n",
    "zeq = KnotPoint(xeq,ueq,dt)   # create a `KnotPoint` type that stores everything together\n",
    "∇f = RobotDynamics.DynamicsJacobian(model)\n",
    "jacobian!(∇f, model, zeq)\n",
    "discrete_jacobian!(RK4, ∇f, model, zeq)\n",
    "\n",
    "# Extract pieces of the Jacobian\n",
    "A = ∇f.A\n",
    "B = ∇f.B;\n",
    "\n",
    "# Cost matrices (using Bryson's Rule)\n",
    "Q = Diagonal([\n",
    "    1.0/5^2; \n",
    "    1.0/5^2; \n",
    "    1.0/(10*pi/180)^2; \n",
    "    10.0/5^2; \n",
    "    10.0/5^2; \n",
    "    10.0/(10*pi/180)^2;\n",
    "    1/(.1*model.m*model.g)^2; \n",
    "    1/(10*pi/180)^2\n",
    "])\n",
    "R = Diagonal([\n",
    "    1/(20*model.m*model.g)^2,\n",
    "    1/(deg2rad(10))^2\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a): Design a reference trajectory (3 pts)\n",
    "As we saw in previous problem, we'll need a reference trajectory for our controller. However, in this case our reference trajectory is a very simple trajectory that provides a reasonable guess but we expect the actual solution to be different. We'll later see how this reference trajectory affects the performance of our controller.\n",
    "\n",
    "For the rocket problem, we'll be starting at an altitude of 500m and 200m to the West of our landing location. We'll use a simple linear interpolation from our expected initial state and our goal location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: implement this method (3 pts)\n",
    "\"\"\"\n",
    "    nominal_trajectory(x0, N, dt)\n",
    "\n",
    "Generate the nominal trajectory for the rocket problem, given the initial state `x0`,\n",
    "horizon length `N`, and time step `dt`. \n",
    "\n",
    "The guess should be a linear interpolation of the positions.\n",
    "The velocities should should be consistent with the positions (i.e. constant).\n",
    "The last state should be have position and velocity of 0, but the same nominal\n",
    "actuator commands as initial state (i.e. T and ϕ should be constant)\n",
    "\n",
    "**TIP**: Use a simple finite difference to calculate the velocities.\n",
    "\"\"\"\n",
    "function nominal_trajectory(x0,N,dt)\n",
    "    Xref = [zero(x0) for k = 1:N]\n",
    "    \n",
    "    # TODO: Design a trajectory that linearly interpolates from x0 to the origin\n",
    "    \n",
    "    # Convert to static arrays for plotting\n",
    "    return SVector{8}.(Xref)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start 500m off the ground and 200m West\n",
    "x0_ref = [-200, 500, 0, 0, 0, 0, 0, 0.] + xeq\n",
    "\n",
    "# Generate reference trajectory\n",
    "Xref = nominal_trajectory(x0_ref,N,dt)\n",
    "Uref = [copy(ueq) for k = 1:N]\n",
    "tref = range(0,tf, length=N)\n",
    "\n",
    "# Plot the trajectory\n",
    "traj2(Xref, xlabel=\"x (m)\", ylabel=\"altitude (m)\", label=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b): Design an LQR Controller (5 pts)\n",
    "As we saw in Q1, a simple infinite-gain LQR controller can work extremely effectively. Write a method to calculate the infinite-horizon gain `K` and cost-to-go `P`. We'll use `K` to control our system and `P` as the $Q_f$ weight matrix for our MPC controller later.\n",
    "\n",
    "**EXTRA CREDIT**:\n",
    "The simplest method to calculate the infinite-horizon LQR solution is to just the finite-horizon recursion until it converges to a steady-state value. However, there are other methods. We'll offer extra to anyone who implements an alternative method to running the Riccati recursion until convergence. Simply calling `dlqr` in ControlSystems.jl will not count. You're welcome to use it to check your solution, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Implement the following methods:\n",
    "#       get_control  (3 pts)\n",
    "#       lqr          (2 pts)\n",
    "\n",
    "\"\"\"\n",
    "    LQRController\n",
    "\n",
    "Type for evaluting an infinite-horizon time-invariant LQR control policy. \n",
    "\"\"\"\n",
    "struct LQRController\n",
    "    K::Matrix{Float64}\n",
    "    Xref::Vector{Vector{Float64}}\n",
    "    Uref::Vector{Vector{Float64}}\n",
    "    times::Vector{Float64}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    get_k(ctrl, t)\n",
    "\n",
    "Get the time index corresponding to time `t`. \n",
    "Useful for implementing zero-order hold control.\n",
    "Uses binary search to find the time index.\n",
    "\"\"\"\n",
    "get_k(controller, t) = searchsortedlast(controller.times, t)\n",
    "\n",
    "\"\"\"\n",
    "    get_control(ctrl, x, t)\n",
    "\n",
    "Evaluate the LQR feedback policy at state `x` and time `t`, returning the control \n",
    "to be executed by the system.\n",
    "\"\"\"\n",
    "function get_control(ctrl::LQRController, x, t)\n",
    "    # TODO: Implement the control policy\n",
    "    u = zero(ctrl.Uref[1])\n",
    "    return u\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    lqr(A,B,Q,R; kwargs...)\n",
    "\n",
    "Calculate the infinite-horizon LQR gain from dynamics Jacobians `A` and `B` and\n",
    "cost matrices `Q` and `R`. Returns the infinite-horizon gain `K` and cost-to-go `P`.\n",
    "\n",
    "# Keyword Arguments\n",
    "* `P`: Provide an initial guess for the infinite-horizon gain\n",
    "* `max_iters`: maximum number of iterations\n",
    "* `tol`: tolerance for solve\n",
    "` `verbose`: print the number of iterations\n",
    "\"\"\"\n",
    "function lqr(A,B,Q,R; P=Matrix(Q), tol=1e-8, max_iters=400, verbose=false)\n",
    "    # initialize the output\n",
    "    n,m = size(B)\n",
    "    K = zeros(m,n)\n",
    "    \n",
    "    # TODO: calculate the infinite-horizon LQR solution\n",
    "    \n",
    "    # return the feedback gains and ctg matrices\n",
    "    return K,P\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LQR controller\n",
    "K,Qf = lqr(A,B,Q,R)\n",
    "ctrl = LQRController(K,Xref,Uref,tref);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate and visualize the result\n",
    "vis = initialize_visualizer(model)\n",
    "render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlqr,Ulqr,tlqr = simulate(model, Xref[1], ctrl, tf=50)\n",
    "visualize!(vis, model, tlqr[end] / 10, Xlqr)  # divide the time to speed it up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c): Design an MPC Controller (30 pts)\n",
    "We'll now design QP-based MPC controller for our rocket. We've set up the basic structure below, which is already setup to work with OSQP. Your job is to generate the QP OSQP will need to solve at each iteration.\n",
    "\n",
    "Your QP should look something like this:\n",
    "$$ \\begin{align}\n",
    "    &\\text{minimize}_{z} && \\frac{1}{2} z^T P z + q^T z \\\\\n",
    "    &\\text{subject to} && D z = d \\\\\n",
    "    &&& C z \\leq d \\\\\n",
    "\\end{align} $$\n",
    "\n",
    "where $z$ is the concatenated vector of states and controls at each time step. The equality constraints are just the linearized dynamics constraints:\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "    B & -I \\\\ \n",
    "      & A & B & -I \\\\\n",
    "      &   &   &   & \\ddots \\\\\n",
    "      &   &   &   & & A & B -I \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} u_1 \\\\ x_2 \\\\ u_2 \\\\ \\vdots \\\\ x_{N-1} \\\\ u_{N-1} \\\\ x_N \\end{bmatrix} = \n",
    "\\begin{bmatrix} -A (x_1 - x_{eq}) \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and the cost matrices $P$ and $q$ look are defined as:\n",
    "$$\n",
    "P = \\begin{bmatrix}\n",
    "R \\\\\n",
    "& Q \\\\\n",
    "&& \\ddots \\\\\n",
    "&&& R \\\\\n",
    "&&&& Q_f\n",
    "\\end{bmatrix}, \\quad\n",
    "q = \\begin{bmatrix}\n",
    "    -R(\\bar{u}_1 - u_{eq}) \\\\\n",
    "    -Q(\\bar{x}_2 - x_{eq}) \\\\\n",
    "    \\vdots \\\\\n",
    "    -R(\\bar{u}_{N-1} - u_{eq}) \\\\\n",
    "    -Q_f(\\bar{x}_N - x_{eq}) \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Note that the states and controls in our QP are defined relative to our linearization point at the origin $(x_{eq}, u_{eq})$. As the MPC progresses along the horizon, the reference states and controls $(\\bar{x},\\bar{u})$ will change. Note that in our setup, all of our reference controls are the same, so $\\bar{u}_k - u_{eq} = 0$ for all time steps $k$.\n",
    "\n",
    "We won't have inequality constraints in this part, but we'll add them in the next section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Implement the following methods:\n",
    "#       build_QP!   (15 pts)\n",
    "#       update_QP!  (15 pts)\n",
    "\"\"\"\n",
    "    MPCController\n",
    "\n",
    "An MPC controller that uses a solver of type `S` to solve a QP at every iteration.\n",
    "\n",
    "It will track the reference trajectory specified by `Xref`, `Uref` and `times` \n",
    "with an MPC horizon of `Nmpc`. It will track the terminal reference state if \n",
    "the horizon extends beyond the reference horizon.\n",
    "\"\"\"\n",
    "struct MPCController{S}\n",
    "    P::SparseMatrixCSC{Float64,Int}\n",
    "    q::Vector{Float64}\n",
    "    A::SparseMatrixCSC{Float64,Int}\n",
    "    lb::Vector{Float64}\n",
    "    ub::Vector{Float64}\n",
    "    Nmpc::Int\n",
    "    solver::S\n",
    "    Xref::Vector{Vector{Float64}}\n",
    "    Uref::Vector{Vector{Float64}}\n",
    "    times::Vector{Float64}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    OSQPController(n,m,N,Nref,Nd)\n",
    "\n",
    "Generate an `MPCController` that uses OSQP to solve the QP.\n",
    "Initializes the controller with matrices consistent with `n` states,\n",
    "`m` controls, and an MPC horizon of `N`, and `Nref` constraints. \n",
    "\n",
    "Use `Nref` to initialize a reference trajectory whose length may differ from the \n",
    "horizon length.\n",
    "\"\"\"\n",
    "function OSQPController(n::Integer, m::Integer, N::Integer, Nref::Integer=N, Nd::Integer=(N-1)*n)\n",
    "    Np = (N-1)*(n+m)   # number of primals\n",
    "    P = spzeros(Np,Np)\n",
    "    q = zeros(Np)\n",
    "    A = spzeros(Nd,Np)\n",
    "    lb = zeros(Nd)\n",
    "    ub = zeros(Nd)\n",
    "    Xref = [zeros(n) for k = 1:Nref]\n",
    "    Uref = [zeros(m) for k = 1:Nref]\n",
    "    tref = zeros(Nref)\n",
    "    solver = OSQP.Model()\n",
    "    MPCController{OSQP.Model}(P,q, A,lb,ub, N, solver, Xref, Uref, tref)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    buildQP!(ctrl, A,B,Q,R,Qf; kwargs...)\n",
    "\n",
    "Build the QP matrices `P` and `A` for the MPC problem. Note that these matrices\n",
    "should be constant between MPC iterations.\n",
    "\n",
    "Any keyword arguments will be passed to `initialize_solver!`.\n",
    "\"\"\"\n",
    "function buildQP!(ctrl::MPCController, A,B,Q,R,Qf; kwargs...)\n",
    "    # TODO: Implement this method to build the QP matrices\n",
    "    \n",
    "    # Initialize the included solver\n",
    "    #    If you want to use your QP solver, you should write your own\n",
    "    #    method for this function\n",
    "    initialize_solver!(ctrl; kwargs...)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    initialize_solver!(ctrl::MPCController; kwargs...)\n",
    "\n",
    "Initialize the internal solver once the QP matrices are initialized in the \n",
    "controller.\n",
    "\"\"\"\n",
    "function initialize_solver!(ctrl::MPCController{OSQP.Model}; tol=1e-6, verbose=false)\n",
    "    OSQP.setup!(ctrl.solver, P=ctrl.P, q=ctrl.q, A=ctrl.A, l=ctrl.lb, u=ctrl.ub, \n",
    "        verbose=verbose, eps_rel=tol, eps_abs=tol, polish=1)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    update_QP!(ctrl::MPCController, x, time)\n",
    "\n",
    "Update the vectors in the QP problem for the current state `x` and time `time`.\n",
    "This should update `ctrl.q`, `ctrl.lb`, and `ctrl.ub`.\n",
    "\"\"\"\n",
    "function update_QP!(ctrl::MPCController, x, time)\n",
    "    # TODO: Implement this method\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    get_control(ctrl::MPCController, x, t)\n",
    "\n",
    "Get the control from the MPC solver by solving the QP. \n",
    "If you want to use your own QP solver, you'll need to change this\n",
    "method.\n",
    "\"\"\"\n",
    "function get_control(ctrl::MPCController{OSQP.Model}, x, time)\n",
    "    # Update the QP\n",
    "    update_QP!(ctrl, x, time)\n",
    "    OSQP.update!(ctrl.solver, q=ctrl.q, l=ctrl.lb, u=ctrl.ub)\n",
    "\n",
    "    # Solve QP\n",
    "    results = OSQP.solve!(ctrl.solver)\n",
    "    Δu = results.x[1:2]\n",
    "    \n",
    "    k = get_k(ctrl, time)\n",
    "    return ctrl.Uref[k] + Δu \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unconstrained MPC problem\n",
    "Nmpc = 51           # MPC Horizon\n",
    "mpc1 = OSQPController(n, m, Nmpc, length(Xref))\n",
    "\n",
    "# Provide the reference trajectory\n",
    "mpc1.Xref .= Xref\n",
    "mpc1.Uref .= Uref\n",
    "mpc1.times .= tref\n",
    "\n",
    "# Build the sparse QP matrices\n",
    "buildQP!(mpc1, A,B,Q,R,Qf, tol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmpc1,Umpc1,tmpc1 = simulate(model, Xref[1], mpc1, tf=50)\n",
    "visualize!(vis, model, tmpc1[end] / 10, Xmpc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Results\n",
    "Let's look at some plots to see how our LQR and MPC solutions compare.\n",
    "\n",
    "What do you see? How do the solutions differ? Can you see how the MPC controller is \"looking ahead?\" \n",
    "\n",
    "Your MPC results should be better than your simple LQR controller, but it will still be violating the constraints. Let's add some constraints to our QP to try to fix that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(model, (Xlqr,Ulqr,tlqr,\"LQR\"), (Xmpc1,Umpc1,tmpc1,\"MPC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (d): Add in Constraints (12 pts)\n",
    "Add the following constraints to your optimization problem:\n",
    "$$\\begin{align}\n",
    "    |\\theta | &\\leq 5^{\\circ} \\\\\n",
    "    |\\phi| & \\leq 10^{\\circ} \\\\\n",
    "    z &\\geq 0 \\\\\n",
    "    0.75 &\\leq \\frac{1}{mg} T \\leq 1.5\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**TASK (12 pts)**: Modify the `build_QP` and `update_QP` methods above to add in the  constraints . You should add some logic that checks only adds the constraints if there's room in the matrices, that way we can still use the method to generate our unconstrained solver. See code below for the expected way to initialize the contrained solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constrained MPC controller\n",
    "Nd = (Nmpc-1)*(n+4)\n",
    "mpc2 = OSQPController(n, m, Nmpc, length(Xref), Nd)\n",
    "mpc2.Xref .= Xref\n",
    "mpc2.Uref .= Uref\n",
    "mpc2.times .= tref\n",
    "buildQP!(mpc2, A,B,Q,R,Qf, tol=1e-2, verbose=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmpc2,Umpc2,tmpc2 = simulate(model, Xref[1], mpc2, tf=50)\n",
    "visualize!(vis, model, tmpc2[end] / 10, Xmpc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results\n",
    "Let's check our plots again to see how we did! You should see that the solution now (mostly) satisfies the constraints. You should notice that it violates the roll angle limit slightly. Why do you think that is? Is there a way we could prevent that? In the next (and last) section, we'll explore the effects of changing the MPC horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(model, (Xlqr,Ulqr,tlqr,\"LQR\"), (Xmpc1,Umpc1,tmpc1,\"MPC\"), (Xmpc2,Umpc2,tmpc2,\"MPC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (e): Changing the Horizon (0 pts)\n",
    "Let's see how our solution changes with the horizon. Note, there's nothing we're asking you to do here, just take minute to look at the plots and convince yourself of what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with a 1-step horizon\n",
    "Nmpc = 2\n",
    "\n",
    "# Constrained MPC\n",
    "mpc3 = OSQPController(n, m, Nmpc, length(Xref))\n",
    "mpc3.Xref .= Xref\n",
    "mpc3.Uref .= Uref\n",
    "mpc3.times .= tref\n",
    "buildQP!(mpc3, A,B,Q,R,Qf, tol=1e-2, verbose=false)\n",
    "Xmpc3,Umpc3,tmpc3 = simulate(model, Xref[1], mpc3, tf=50)\n",
    "\n",
    "# Constrained MPC\n",
    "Nd = (Nmpc-1)*(n+4)\n",
    "mpc4 = OSQPController(n, m, Nmpc, length(Xref), Nd)\n",
    "mpc4.Xref .= Xref\n",
    "mpc4.Uref .= Uref\n",
    "mpc4.times .= tref\n",
    "buildQP!(mpc4, A,B,Q,R,Qf, tol=1e-2, verbose=false)\n",
    "Xmpc4,Umpc4,tmpc4 = simulate(model, Xref[1], mpc4, tf=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(model, (Xlqr,Ulqr,tlqr,\"LQR\"), (Xmpc3,Umpc3,tmpc3,\"MPC\"), (Xmpc4,Umpc4,tmpc4,\"MPC-Con\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with a bunch of horizons\n",
    "horizons = [21,31,41,51,61,71,81,91,101]\n",
    "\n",
    "Z = map(horizons) do Nmpc\n",
    "    # Constrained MPC\n",
    "    println(\"running with horizon = $Nmpc\")\n",
    "    Nd = (Nmpc-1)*(n+4)\n",
    "    mpc = OSQPController(n, m, Nmpc, length(Xref), Nd)\n",
    "    mpc.Xref .= Xref\n",
    "    mpc.Uref .= Uref\n",
    "    mpc.times .= tref\n",
    "    buildQP!(mpc, A,B,Q,R,Qf, tol=1e-2, verbose=false)\n",
    "    Xmpc,Umpc,tmpc = simulate(model, Xref[1], mpc, tf=50);\n",
    "    (Xmpc,Umpc,tmpc,\"N = \" * string(Nmpc))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(model, Z...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: Use your QP Solver (max 10 pts)\n",
    "You can earn some extra credit by using the AL QP solver you built in the previous homework. You'll get more extra credit if you modify your QP solver to handle the unique structure that exists in the MPC QP problem. Include an example of using your QP solver below, along with a description of your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
